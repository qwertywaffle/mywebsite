<!DOCTYPE html>
<html>
<head>
  <title>image to audio</title>
  <style>
    canvas#oscilloscope {
      border: 1px solid #ccc;
      width: 100%;
      height: 150px;
      display: block;
    }
  </style>
</head>
<body>
  <h2>image to audio (compatible files only)</h2>
  <input type="file" id="imageInput" accept="image/*" /><br><br>
  <canvas id="canvas" style="display:none;"></canvas>
  <canvas id="oscilloscope" width="800" height="150"></canvas><br>
  <button onclick="playAudio()">play audio</button>

  <script>
    let audioBuffer = null;
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioCtx.createAnalyser();
    let sourceNode = null;

    const canvas = document.getElementById('canvas');
    const oscCanvas = document.getElementById('oscilloscope');
    const oscCtx = oscCanvas.getContext('2d');

    function drawOscilloscope() {
      const bufferLength = analyser.fftSize;
      const dataArray = new Uint8Array(bufferLength);

      function drawFrame() {
        setTimeout(() => {
          requestAnimationFrame(drawFrame);
          analyser.getByteTimeDomainData(dataArray);
          oscCtx.fillStyle = '#111';
          oscCtx.fillRect(0, 0, oscCanvas.width, oscCanvas.height);

          let sum = 0;
          for (let i = 0; i < bufferLength; i++) sum += dataArray[i];
          const avg = sum / bufferLength;

          oscCtx.lineWidth = 2;
          oscCtx.strokeStyle = '#00ff88';
          oscCtx.beginPath();

          const sliceWidth = oscCanvas.width / bufferLength;
          let x = 0;
          for (let i = 0; i < bufferLength; i++) {
            const v = (dataArray[i] - avg) / 128.0;
            const y = (v * oscCanvas.height / 2) + (oscCanvas.height / 2);
            if (i === 0) oscCtx.moveTo(x, y);
            else oscCtx.lineTo(x, y);
            x += sliceWidth;
          }
          oscCtx.stroke();
        }, 1000 / 60);
      }

      drawFrame();
    }

    drawOscilloscope();

    document.getElementById('imageInput').addEventListener('change', function () {
      const file = this.files[0];
      const img = new Image();
      const url = URL.createObjectURL(file);
      img.src = url;

      img.onload = () => {
        const ctx = canvas.getContext('2d');
        canvas.width = img.width;
        canvas.height = img.height;
        ctx.drawImage(img, 0, 0);
        const imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const data = imgData.data;

        let sampleRate = (data[0] << 8) + data[1];
        if (sampleRate < 3000 || sampleRate > 96000) {
          sampleRate = 44100;
          console.warn("Invalid metadata. Using 44100 Hz.");
        }

        try {
          const sampleBytes = data.slice(4); // Skip first pixel (metadata)
          const sampleCount = sampleBytes.length;
          const samples = new Float32Array(sampleCount);
          for (let i = 0; i < sampleCount; i++) {
            samples[i] = (sampleBytes[i] / 127.5) - 1;
          }

          audioBuffer = audioCtx.createBuffer(1, samples.length, sampleRate);
          audioBuffer.copyToChannel(samples, 0);
          console.log(`Decoded ${samples.length} samples at ${sampleRate} Hz`);
        } catch (e) {
          audioBuffer = null;
          alert("Error decoding image audio.");
        }
      };
    });

    function playAudio() {
      if (!audioBuffer) {
        alert("No valid audio loaded.");
        return;
      }

      if (sourceNode) sourceNode.disconnect();

      sourceNode = audioCtx.createBufferSource();
      sourceNode.buffer = audioBuffer;
      sourceNode.connect(analyser);
      analyser.connect(audioCtx.destination);
      sourceNode.start();
    }
  </script>
</body>
</html>
